
# Hand Signs Project
## Project presentation and poster

 -  [Presentation](presentation.pptx).
 -  [Poster](poster.pdf).

## Background and Rationale
Sign language is a visual communication system designed for individuals with hearing impairments, relying on hand movements, facial expressions, and body language to convey messages accurately and fluidly. The body parts involved include hands, fingers, eyes, and face, which contribute to the creation of diverse and complex expressions in this language.

Due to the communication barrier between hearing individuals and those with hearing impairments, particularly among children with hearing and speech disabilities, there is a need for early learning of sign language by children and their families. This learning can reduce the communication barrier and facilitate their social integration.

The integration of modern technologies such as machine learning, deep learning, and computer vision offers an innovative solution for making the learning of sign language more accessible. These technologies can lead to personalized learning processes, enhance educational efficiency, and assist in acquiring new knowledge quickly and interactively.

## Objective
To develop an innovative software platform for learning the fundamentals of American Sign Language (ASL), featuring an interactive interface based on machine learning and computer vision technologies.

## Tasks to Achieve the Objective
#### Development of an Algorithmic Model for Hand Gesture Recognition:
The application will identify the userâ€™s hand movements using a camera, compare them to stored examples of sign language gestures in the system's database, and provide real-time feedback on the accuracy of the current task.

#### Development of an Algorithmic Model for Speech Learning:
This model will allow for the use of voice as a tool for learning the letters and their shapes in sign language, by comparing the spoken letter by the user to the corresponding hand gesture image. This tool is intended especially for family members, educators, and the learner's environment, rather than for the children themselves, to indirectly support the learning of sign language.

#### Creating a User Interface:
A colorful and eye-catching graphic design with an intuitive and easy-to-use interface.
#### Creating Interactive Features for Practice:
Interactive games to reinforce learning and track progress.

## Technologies Used
#### Programming Languages:
`Python`, `JavaScript`, `HTML`, `CSS`

#### Libraries:
##### Machine Learning:
`Keras` `TensorFlow` `OpenCV` `MediaPipe` `NumPy` `Pandas` `Matplotlib`

##### Web:
`Flask` `BeautifulSoup` `PyAudio` `SpeechRecognition`

## Installation
### To install the project and its dependencies, follow these steps:


## Run Locally

Clone the project

```bash
  git clone https://github.com/yourusername/HandSignsProject.git
```

Go to the project directory

```bash
  cd HandSignsProject
```

Install the requirements.txt file

```bash
pip install -r requirements.txt
```

To run the application, execute the following command in your terminal

```bash
 python app.py
```



